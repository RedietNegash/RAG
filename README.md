1. ## **Document Query System**

## Overview
This project showcases an intelligent document query system using **LlamaIndex** that efficiently retrieves relevant sections from large text collections, such as books, and generates accurate responses with **Large Language Models (LLMs)**. The system incorporates **Sentence Retrieval**, which indexes documents at the sentence level to enhance precision in identifying the most relevant information, and **Auto-Merging**, which automatically combines contextually related sentences to produce cohesive answers. Additionally, a feedback mechanism is integrated to ensure continuous improvement in response quality, making the system more effective over time.

## Key Features
•	LlamaIndex Integration: Utilizes LlamaIndex for effective document indexing and retrieval, enabling fast and accurate access to relevant sections of large text collections.

•	Sentence Retrieval: Breaks down documents into individual sentences or smaller chunks, allowing for fine-grained querying and retrieval of specific information.

•	Auto-Merging: Automatically combines related sentences or text chunks into coherent, contextually unified responses, enhancing the clarity and completeness of the answers.

•	LLM-Powered Responses: Leverages Large Language Models (LLMs) to generate contextually accurate and insightful answers based on the retrieved information, providing users with high-quality responses.

•	Feedback Mechanism: Incorporates a feedback system to collect and analyze user input, enabling continuous improvement of response quality and system performance over time.


## Setup

### Install Dependencies

To set up the project, you'll need to install several Python packages. Use the following commands to ensure all necessary libraries are installed:

```bash
pip install trulens-eval llama-index llama-index-embeddings-huggingface torch sentence-transformers datasets generativeai trulens-providers-huggingface qdrant-client chromadb llama-index-vector-stores-chroma transformers
```

### Hugging Face Configuration

1. **Obtain Access Token:** Sign up or log in to your Hugging Face account and obtain an access token from the [Hugging Face Hub](https://huggingface.co/settings/tokens). This token will be used for authentication when accessing models and APIs.

2. **Initialize Hugging Face Model:** Configure the `HuggingFaceInferenceAPI` using your Hugging Face access token. This client will be used for generating embeddings and responses. Use the `HuggingFaceEmbedding` for generating embeddings and `HuggingFaceInferenceAPI` for generating responses from the model.

### LlamaIndex Setup

1. **Initialize LlamaIndex Components:** Set up LlamaIndex components, including document loaders, node parsers, and vector store indices. Configure the `Document`, `SimpleDirectoryReader`, `SentenceWindowNodeParser`, and `VectorStoreIndex` to handle document processing and retrieval.

2. **Node Parsing and Indexing:** Use `SentenceWindowNodeParser` or `HierarchicalNodeParser` to split documents into manageable chunks. Create and configure a `VectorStoreIndex` to store and retrieve these chunks efficiently.

### Vector Storage Setup

1. **Configure Vector Store:** Set up your vector storage using Chroma or any other supported vector store. Ensure it is properly initialized and connected to handle the storage and retrieval of embeddings.

### Document Processing

1. **Document Loading:** Use a document loader (e.g., `SimpleDirectoryReader`) to import documents.
2. **Chunking:** Apply a text chunking strategy (e.g., `SentenceWindowNodeParser` or `HierarchicalNodeParser`) to split documents into manageable chunks for embedding.

### Embedding and Storage

1. **Generate Embeddings:** Convert text chunks into embeddings using the `HuggingFaceEmbedding` model from LlamaIndex.
2. **Store Vectors:** Save these embeddings into the vector store. This includes creating and configuring the index for efficient retrieval.

### Query Handling

1. **Augment Queries:** Enhance user queries by integrating relevant context retrieved from the vector store. This step improves the quality of the responses.
2. **Generate Responses:** Use the Hugging Face model to generate responses based on the augmented query context. Configure the `HuggingFaceInferenceAPI` for this purpose.

### Auto-Merging Retrieval

1. **Setup Auto-Merging Retriever:** Configure the `AutoMergingRetriever` from LlamaIndex to handle merging of query results from various retrieval methods, enhancing the response quality with a combination of results.

### Evaluation

1. **Configure Evaluation:** Use `TruLens` to set up evaluation and feedback mechanisms. This includes configuring feedback mechanisms to assess the relevance and quality of responses generated by the system.


